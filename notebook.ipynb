{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes classifier for spam detection\n",
    "\n",
    "[Python refresher exercise](http://misza222.github.io/ml/2018/04/02/how-to-refresh-my-python-skills.html) for me. Data from a [kaggle](https://www.kaggle.com/uciml/sms-spam-collection-dataset#), idea from [Raj'es video](https://www.youtube.com/watch?v=PrkiRVcrxOs)\n",
    "\n",
    "Compare results with [this kernel on Kaggle](https://www.kaggle.com/muzzzdy/sms-spam-detection-with-various-classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pandas used for importing csv only - forgot how to deal with those beautiful animals - to be refreshed later\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./spam.csv\", encoding = \"ISO-8859-1\")\n",
    "df = df[['v1', 'v2']]\n",
    "df.columns = ['class', 'sms']\n",
    "df_test = df[-100:]\n",
    "df_train = df[:-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import operator, functools\n",
    "\n",
    "class SpamModel:\n",
    "        \n",
    "    def fit(self, df):\n",
    "        \"\"\"\n",
    "        Fitting method will compute necessary statistics, but what do we need?\n",
    "         \n",
    "        P(ham|sms) = np.prod([P(ham|word) for word in sms])\n",
    "        P(spam|sms) = np.prod([P(spam|word) for word in sms])\n",
    "        \n",
    "        P(ham|word) = P(ham) * P(word|ham) / P(word) \n",
    "        P(spam|word) = P(spam) * P(word|spam) / P(word) \n",
    "        in fact in the equasions above we can ommit division by P(word)\n",
    "        as for spam we do the same divisions, so it won't impact the result\n",
    "        \n",
    "        P(spam) = 1 - P(ham)\n",
    "        P(spam) = # spam / # total\n",
    "        \n",
    "        P(word) =\n",
    "        \n",
    "        P(word|spam) = \n",
    "        P(word|ham) =\n",
    "        \"\"\"\n",
    "    \n",
    "        self.df_raw_data = self.df_to_array(df)\n",
    "        self.training_size = len(self.df_raw_data)\n",
    "        \n",
    "        self.nr_of_spam = sum([key == \"spam\" for key, value in self.df_raw_data])\n",
    "        self.nr_of_ham = sum([key == \"ham\" for key, value in self.df_raw_data])\n",
    "        \n",
    "        self.df_tokenized_data = list(map(lambda elem: (elem[0], self.tokenize(elem[1])), self.df_raw_data))\n",
    "        self.df_counted_data = list(map(lambda elem: (elem[0], Counter(elem[1])), self.df_tokenized_data))\n",
    "        \n",
    "#         print([elem[1] for elem in self.df_counted_data if elem[0] == 'spam'])\n",
    "        \n",
    "        self.spam_counted_data = sum(\n",
    "            [elem[1] for elem in self.df_counted_data if elem[0] == 'spam'],\n",
    "            Counter()\n",
    "        )\n",
    "        self.spam_total_words = sum(self.spam_counted_data.values())\n",
    "\n",
    "        self.ham_counted_data = sum(\n",
    "            [elem[1] for elem in self.df_counted_data if elem[0] == 'ham'],\n",
    "            Counter()\n",
    "        )\n",
    "        self.ham_total_words = sum(self.ham_counted_data.values())\n",
    "        \n",
    "        self.counted_data = self.spam_counted_data + self.ham_counted_data\n",
    "        \n",
    "    def predict(self, sms):\n",
    "        \"\"\"\n",
    "        Predict computes probabilities for spam and not spam and chooses the larger number to report the result\n",
    "        \"\"\"\n",
    "        words = self.tokenize(sms)\n",
    "        \n",
    "        spam_prediction = self.predict_words_for(\"spam\", words)\n",
    "        ham_prediction = self.predict_words_for(\"ham\", words)\n",
    "        \n",
    "        if spam_prediction > ham_prediction:\n",
    "            return \"spam\"\n",
    "        else:\n",
    "            return \"ham\"\n",
    "        \n",
    "    def predict_words_for(self, clas, words):\n",
    "        \"\"\"\n",
    "        Here we compute:\n",
    "        P(clas|sms) = np.prod([P(clas|word) for word in sms])\n",
    "        \n",
    "        where:\n",
    "        P(clas|word) = P(clas) * P(word|clas) / P(word) \n",
    "        \n",
    "        \"\"\"\n",
    "        if clas == \"spam\":\n",
    "            counters = self.spam_counted_data\n",
    "            total = self.spam_total_words\n",
    "            class_probability = self.nr_of_spam / self.training_size\n",
    "        else:\n",
    "            counters = self.ham_counted_data\n",
    "            total = self.ham_total_words\n",
    "            class_probability = self.nr_of_ham / self.training_size\n",
    "        \n",
    "        \n",
    "        probabilities = [\n",
    "            # P(clas|word) = P(clas) * P(word|clas) / P(word) \n",
    "            class_probability * self.training_size * (counters[word] + 1) / total / (self.counted_data[word] + 1)\n",
    "            for word in words\n",
    "        ]\n",
    "        \n",
    "        return functools.reduce(\n",
    "                    operator.mul,\n",
    "                    probabilities,\n",
    "                    1\n",
    "                )\n",
    "        \n",
    "    def tokenize(self, strng):\n",
    "        \"\"\"Naive tokenization method\"\"\"\n",
    "        return strng.split(\" \")\n",
    "    \n",
    "    def df_to_array(self, df):\n",
    "        \"\"\"Convert DataFram to plain python array, as forgot how to handle pandas\"\"\"\n",
    "        data_array = []\n",
    "        for _, row in df.iterrows():\n",
    "            data_array.append((row['class'], row['sms']))\n",
    "            \n",
    "        return data_array\n",
    "    \n",
    "sm = SpamModel()\n",
    "sm.fit(df_train)\n",
    "\n",
    "# print(\"Spam:\", sm.nr_of_spam)\n",
    "# print(\"Ham:\", sm.nr_of_ham)\n",
    "# print(\"spam:\", sm.spam_counted_data[\"to\"])\n",
    "# print(\"ham:\", sm.ham_counted_data[\"to\"])\n",
    "\n",
    "# sm.predict(\"You have won the main price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on a test set is 93%\n"
     ]
    }
   ],
   "source": [
    "# print(sm.predict(\"You have won the main price\"))\n",
    "# print(sm.predict(\"Free entry in 2 a wkly comp to win FA Cup\"))\n",
    "# print(sm.predict(\"SIX chances to win CASH! From 100 to 20,000\"))\n",
    "\n",
    "test_array = sm.df_to_array(df_test) # just convert a dataframe to array\n",
    "\n",
    "# for clas, sms in test_array:\n",
    "#     if clas != sm.predict(sms):\n",
    "#         print(f\"'{sms}' predicted as '{sm.predict(sms)}' is really of class '{clas}'\")\n",
    "\n",
    "# accuracy\n",
    "accuracy = sum([clas == sm.predict(sms) for clas, sms in test_array]) / len(test_array)\n",
    "print(f\"Accuracy on a test set is {round(accuracy * 100)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
